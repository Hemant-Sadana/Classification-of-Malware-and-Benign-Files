#Program to perform validation to determine which features to kept and which model to use.
import numpy as np
from sklearn.svm import LinearSVC as csvm
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression as lr
from sklearn.tree import DecisionTreeClassifier

X = np.load('features.npy')         #loads the newfeatarray created by featextract.py
Y = np.zeros(10238)
for i in range(5125,10238):             #Set the label 0 for benign and 1 for malware
    Y[i]=1
    
#Split the feature array into training and testing part
X_train, X_test, y_train, y_test = train_test_split(X ,Y, test_size = .25, random_state = 100)

#Using Logistic Regression
clf = lr( penalty= "l2", C = 1.0, fit_intercept = True, solver = "liblinear" )
clf.fit( X_train, y_train )

ypred = clf.predict(X_test)
count=0
for i in range(y_test.size):
    if(ypred[i]==y_test[i]):
        count = count+1

acc = count*100/ypred.size
print(acc)

#Using CSVM
clf = csvm( penalty= "l2", loss = "hinge", C = 1, fit_intercept = True )
clf.fit( X_train, y_train)
ypred = clf.predict(X_test)

count=0
for i in range(y_test.size):
    if(ypred[i]==y_test[i]):
        count = count+1

acc = count*100/ypred.size
print(acc)

#Using Decision Tree
clf = DecisionTreeClassifier()
clf.fit(X_train, y_train)
ypred = clf.predict(X_test)

count=0
for i in range(y_test.size):
    if(ypred[i]==y_test[i]):
        count = count+1

acc = count*100/ypred.size
print(acc)
#All gave same results